{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28357ea4-a382-48e6-8d82-ad1a568395d2",
   "metadata": {},
   "source": [
    "# Compare model output with ASTE and observations\n",
    "\n",
    "Load selected mooring time series (see choose_ASTE_profiles), and subsample CANARI LE accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b624e549-040c-4825-9242-264ed87c417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defafc31-43fd-4fb0-bc66-711310246c54",
   "metadata": {},
   "source": [
    "Open all mooring time series and get grid points for subsetting CANARI-LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4385482a-c5df-457f-928e-e9b3b4684c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "mooring_files=glob.glob('../data/*tseries.nc')\n",
    "mooring_vars={}\n",
    "for file in mooring_files:\n",
    "    mooring=xr.open_dataset(file)\n",
    "    if 'iPROF' in mooring.dims:\n",
    "        mooring=mooring.swap_dims({'iPROF':'time'})\n",
    "    mooring=mooring.sortby('time').squeeze()\n",
    "    if 'point' in mooring.dims:\n",
    "        for ip,point in enumerate(mooring.point):\n",
    "            mooring_vars[f'{mooring[\"loc\"].values}_{ip}']=mooring[['prof_T','prof_Testim','prof_S','prof_Sestim']].sel(point=point)\n",
    "    else:\n",
    "        mooring_vars[str(mooring['loc'].values)]=mooring[['prof_T','prof_Testim','prof_S','prof_Sestim']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6cb59-d9db-4567-a044-35599f0e0e7a",
   "metadata": {},
   "source": [
    "Load NEMO T grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07d1f42-0cbf-45da-9da9-0e9e85e6451d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/pydap/lib.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/pkg_resources/__init__.py:2868: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/pkg_resources/__init__.py:2868: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.responses')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/pkg_resources/__init__.py:2348: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/pkg_resources/__init__.py:2868: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.handlers')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/pkg_resources/__init__.py:2348: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/pkg_resources/__init__.py:2868: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.tests')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/pkg_resources/__init__.py:2348: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/utide/harmonics.py:16: RuntimeWarning: invalid value encountered in cast\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/utide/harmonics.py:17: RuntimeWarning: invalid value encountered in cast\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/coast/data/gridded.py:236: UserWarning: The model domain loaded, '/gws/nopw/j04/canari/users/dlrhodso/mesh_mask.nc', does not contain the bathy_metry' variable. This will result in the NEMO.dataset.bathymetry variable being set to zero, which may result in unexpected behaviour from routines that require this variable.\n"
     ]
    }
   ],
   "source": [
    "import coast\n",
    "nemo_dom = \"/gws/nopw/j04/canari/users/dlrhodso/mesh_mask.nc\"\n",
    "\n",
    "config_grid={}\n",
    "config_dir=\"../../tutorials/config\"\n",
    "for grid in ['t','f','u','v']:\n",
    "    config_grid[grid]=f'{config_dir}/example_nemo_grid_{grid}.json'\n",
    "\n",
    "nemo_t = coast.Gridded( fn_domain=nemo_dom, config=config_grid['t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dae3fc-e00e-4209-b5dd-d3c565174703",
   "metadata": {},
   "source": [
    "Find NEMO grid points for all moorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d21fd29-0d44-44fb-8862-3b700d6784e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-08-30T00:00:00.000000000 2016-10-11T00:00:00.000000000\n",
      "2007-09-02T00:00:00.000000000 2011-07-14T00:00:00.000000000\n",
      "2004-09-27T00:00:00.000000000 2013-09-17T00:00:00.000000000\n",
      "2002-08-13T00:00:00.000000000 2012-06-27T00:00:00.000000000\n",
      "2014-08-12T00:00:00.000000000 2016-08-08T00:00:00.000000000\n",
      "2014-08-12T00:00:00.000000000 2016-08-08T00:00:00.000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Beaufort Mooring': <xarray.Dataset>\n",
       " Dimensions:              (time: 3007)\n",
       " Coordinates: (12/21)\n",
       "     prof_descr           (time) |S30 ...\n",
       "     prof_date            (time) float64 ...\n",
       "     prof_YYYYMMDD        (time) float64 ...\n",
       "     prof_HHMMSS          (time) float64 ...\n",
       "     prof_lon             (time) float64 -140.0 -140.0 -140.0 ... -140.1 -140.1\n",
       "     prof_lat             (time) float64 74.0 74.0 74.0 74.0 ... 74.0 74.0 74.0\n",
       "     ...                   ...\n",
       "     prof_interp_lat      (time) float64 ...\n",
       "     prof_interp_weights  (time) float64 ...\n",
       "   * time                 (time) datetime64[ns] 2005-08-30 ... 2016-10-11\n",
       "     depth                float64 ...\n",
       "     loc                  <U16 'Beaufort Mooring'\n",
       "     point                float64 1.134e+06\n",
       " Data variables:\n",
       "     prof_T               (time) float64 ...\n",
       "     prof_Testim          (time) float64 ...\n",
       "     prof_S               (time) float64 ...\n",
       "     prof_Sestim          (time) float64 ...\n",
       "     yy                   int64 1114\n",
       "     xx                   int64 502,\n",
       " 'Bering Mooring': <xarray.Dataset>\n",
       " Dimensions:              (time: 1409)\n",
       " Coordinates: (12/21)\n",
       "     prof_descr           (time) |S30 ...\n",
       "     prof_date            (time) float64 ...\n",
       "     prof_YYYYMMDD        (time) float64 ...\n",
       "     prof_HHMMSS          (time) float64 ...\n",
       "     prof_lon             (time) float64 -169.0 -169.0 -169.0 ... -169.0 -169.0\n",
       "     prof_lat             (time) float64 66.33 66.33 66.33 ... 66.33 66.33 66.33\n",
       "     ...                   ...\n",
       "     prof_interp_lat      (time) float64 ...\n",
       "     prof_interp_weights  (time) float64 ...\n",
       "   * time                 (time) datetime64[ns] 2007-09-02 ... 2011-07-14\n",
       "     depth                float64 ...\n",
       "     loc                  <U14 'Bering Mooring'\n",
       "     point                float64 8.344e+05\n",
       " Data variables:\n",
       "     prof_T               (time) float64 ...\n",
       "     prof_Testim          (time) float64 ...\n",
       "     prof_S               (time) float64 ...\n",
       "     prof_Sestim          (time) float64 ...\n",
       "     yy                   int64 1023\n",
       "     xx                   int64 456,\n",
       " 'Davis Mooring': <xarray.Dataset>\n",
       " Dimensions:              (time: 3278)\n",
       " Coordinates: (12/21)\n",
       "     prof_descr           (time) |S30 ...\n",
       "     prof_date            (time) float64 ...\n",
       "     prof_YYYYMMDD        (time) float64 ...\n",
       "     prof_HHMMSS          (time) float64 ...\n",
       "     prof_lon             (time) float64 -57.68 -57.68 -57.68 ... -57.68 -57.68\n",
       "     prof_lat             (time) float64 66.98 66.98 66.98 ... 66.98 66.98 66.98\n",
       "     ...                   ...\n",
       "     prof_interp_lat      (time) float64 ...\n",
       "     prof_interp_weights  (time) float64 ...\n",
       "   * time                 (time) datetime64[ns] 2004-09-27 ... 2013-09-17\n",
       "     depth                float64 ...\n",
       "     loc                  <U13 'Davis Mooring'\n",
       "     point                float64 8.456e+05\n",
       " Data variables:\n",
       "     prof_T               (time) float64 ...\n",
       "     prof_Testim          (time) float64 ...\n",
       "     prof_S               (time) float64 ...\n",
       "     prof_Sestim          (time) float64 ...\n",
       "     yy                   int64 1039\n",
       "     xx                   int64 948,\n",
       " 'Fram Mooring': <xarray.Dataset>\n",
       " Dimensions:              (time: 3481)\n",
       " Coordinates: (12/21)\n",
       "     prof_descr           (time) |S30 ...\n",
       "     prof_date            (time) float64 ...\n",
       "     prof_YYYYMMDD        (time) float64 ...\n",
       "     prof_HHMMSS          (time) float64 ...\n",
       "     prof_lon             (time) float64 1.612 1.612 1.612 ... 1.598 1.598 1.598\n",
       "     prof_lat             (time) float64 78.83 78.83 78.83 ... 78.83 78.83 78.83\n",
       "     ...                   ...\n",
       "     prof_interp_lat      (time) float64 ...\n",
       "     prof_interp_weights  (time) float64 ...\n",
       "   * time                 (time) datetime64[ns] 2002-08-13 ... 2012-06-27\n",
       "     depth                float64 ...\n",
       "     loc                  <U12 'Fram Mooring'\n",
       "     point                float64 9.257e+05\n",
       " Data variables:\n",
       "     prof_T               (time) float64 ...\n",
       "     prof_Testim          (time) float64 ...\n",
       "     prof_S               (time) float64 ...\n",
       "     prof_Sestim          (time) float64 ...\n",
       "     yy                   int64 1115\n",
       "     xx                   int64 1095,\n",
       " 'OSNAP Mooring_0': <xarray.Dataset>\n",
       " Dimensions:              (time: 728)\n",
       " Coordinates: (12/21)\n",
       "   * time                 (time) datetime64[ns] 2014-08-12 ... 2016-08-08\n",
       "     prof_descr           (time) |S30 ...\n",
       "     prof_date            (time) float64 ...\n",
       "     prof_YYYYMMDD        (time) float64 ...\n",
       "     prof_HHMMSS          (time) float64 ...\n",
       "     prof_lon             (time) float64 -51.32 -51.32 -51.32 ... nan nan nan\n",
       "     ...                   ...\n",
       "     prof_interp_lon      (time) float64 ...\n",
       "     prof_interp_lat      (time) float64 ...\n",
       "     prof_interp_weights  (time) float64 ...\n",
       "     depth                float64 ...\n",
       "     loc                  <U13 ...\n",
       "     point                float64 7.538e+05\n",
       " Data variables:\n",
       "     prof_T               (time) float64 ...\n",
       "     prof_Testim          (time) float64 ...\n",
       "     prof_S               (time) float64 ...\n",
       "     prof_Sestim          (time) float64 ...\n",
       "     yy                   int64 935\n",
       "     xx                   int64 949,\n",
       " 'OSNAP Mooring_1': <xarray.Dataset>\n",
       " Dimensions:              (time: 728)\n",
       " Coordinates: (12/21)\n",
       "   * time                 (time) datetime64[ns] 2014-08-12 ... 2016-08-08\n",
       "     prof_descr           (time) |S30 ...\n",
       "     prof_date            (time) float64 ...\n",
       "     prof_YYYYMMDD        (time) float64 ...\n",
       "     prof_HHMMSS          (time) float64 ...\n",
       "     prof_lon             (time) float64 nan nan -41.74 ... -41.74 -41.74 -41.74\n",
       "     ...                   ...\n",
       "     prof_interp_lon      (time) float64 ...\n",
       "     prof_interp_lat      (time) float64 ...\n",
       "     prof_interp_weights  (time) float64 ...\n",
       "     depth                float64 ...\n",
       "     loc                  <U13 'OSNAP Mooring'\n",
       "     point                float64 7.992e+05\n",
       " Data variables:\n",
       "     prof_T               (time) float64 ...\n",
       "     prof_Testim          (time) float64 ...\n",
       "     prof_S               (time) float64 ...\n",
       "     prof_Sestim          (time) float64 ...\n",
       "     yy                   int64 977\n",
       "     xx                   int64 989}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for mg_co in mooring_vars:\n",
    "    mg_co_ds=mooring_vars[mg_co].squeeze()\n",
    "    mean_lat=mg_co_ds.prof_lat.mean('time')\n",
    "    mean_lon=mg_co_ds.prof_lon.mean('time')\n",
    "    [mg_co_ds['yy'],mg_co_ds['xx']]=nemo_t.find_j_i(lat=mean_lat,lon=mean_lon)\n",
    "    mooring_vars[mg_co]=mg_co_ds\n",
    "    print(mg_co_ds.time.min('time').data,mg_co_ds.time.max('time').data)\n",
    "mooring_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73563c0-66f0-4f84-b139-fb1e1e585694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 587 ms, sys: 111 ms, total: 699 ms\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 10:35:45,184 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import dask_gateway\n",
    "import dask\n",
    "# Create a connection to dask-gateway.\n",
    "gw = dask_gateway.Gateway(\"https://dask-gateway.jasmin.ac.uk\", auth=\"jupyterhub\")\n",
    "\n",
    "# Inspect and change the options if required before creating your cluster.\n",
    "options = gw.cluster_options()\n",
    "options.worker_cores = 1 #keeping this at 1 and allowing 15 worker processes seems to run faster than the other way around\n",
    "options.scheduler_cores = 1 #we need at least one core for the scheduler\n",
    "#specify which conda env to use, this must match the versions of python and dask (and a few other libraries) used on the notebook service\n",
    "options.worker_setup='source /apps/jasmin/jaspy/mambaforge_envs/jaspy3.10/mf-22.11.1-4/bin/activate /gws/smf/j04/canari/dask-env'\n",
    "\n",
    "# Create a dask cluster, or, if one already exists, connect to it.\n",
    "# This stage creates the scheduler job in SLURM, so may take some time.\n",
    "# While your job queues.\n",
    "clusters = gw.list_clusters()\n",
    "if not clusters:\n",
    "    cluster = gw.new_cluster(options, shutdown_on_close=False)\n",
    "else:\n",
    "    cluster = gw.connect(clusters[0].name)\n",
    "\n",
    "# Create at least one worker, and allow your cluster to scale to 15.\n",
    "# The max JASMIN allows is 16, but one of these is used as the scheduler.\n",
    "cluster.adapt(minimum=1, maximum=15)\n",
    "\n",
    "# Get a dask client.\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b74e3-dbf9-494f-9b87-9f70d6d80920",
   "metadata": {},
   "source": [
    "Load all LE members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d254dd-c5df-4377-b771-ec3f5751bf80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, skipping\n",
      "File exists, skipping\n",
      "File exists, skipping\n",
      "File exists, skipping\n",
      "File exists, skipping\n",
      "File exists, skipping\n",
      "File exists, skipping\n",
      "File exists, skipping\n",
      "Doing ensemble member 21\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     temp_Tgrid \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mens_data_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/*_mon__grid_T_votemper.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     sal_Tgrid \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mens_data_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/*_mon__grid_T_vosaline.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     Tdata\u001b[38;5;241m.\u001b[39mappend(xr\u001b[38;5;241m.\u001b[39mopen_mfdataset([\u001b[43mtemp_Tgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,sal_Tgrid[\u001b[38;5;241m0\u001b[39m]]))\n\u001b[1;32m     16\u001b[0m Tdata\u001b[38;5;241m=\u001b[39mxr\u001b[38;5;241m.\u001b[39mconcat(Tdata,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_counter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m datetimeindex \u001b[38;5;241m=\u001b[39m Tdata\u001b[38;5;241m.\u001b[39mindexes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_counter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_datetimeindex()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data_path = \"/gws/nopw/j04/canari/shared/large-ensemble/priority/HIST2\"\n",
    "ensembles=glob.glob(f'{data_path}/*')\n",
    "for ens_file in ensembles:\n",
    "    ens=int(ens_file.split('/')[-1])\n",
    "    if glob.glob(f'../data/mooring_tseries_ens{ens}.nc'):\n",
    "        print(f'File for {ens} exists, skipping')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'Doing ensemble member {ens}')\n",
    "    ens_data_path=f'{data_path}/{ens}/OCN/yearly'\n",
    "    Tdata=[]\n",
    "    for year in range(2000,2015):\n",
    "        temp_Tgrid = glob.glob(f\"{ens_data_path}/{year}/*_mon__grid_T_votemper.nc\")\n",
    "        sal_Tgrid = glob.glob(f\"{ens_data_path}/{year}/*_mon__grid_T_vosaline.nc\")\n",
    "        try:\n",
    "            Tdata.append(xr.open_mfdataset([temp_Tgrid[0],sal_Tgrid[0]]))\n",
    "        except:\n",
    "            print(f'No data for member {ens}, year {year}')\n",
    "            continue\n",
    "    if Tdata:\n",
    "        Tdata=xr.concat(Tdata,'time_counter')\n",
    "    else:\n",
    "        print(f'Tdata empty, skipping {ens} entirely')\n",
    "        continue\n",
    "    datetimeindex = Tdata.indexes['time_counter'].to_datetimeindex()\n",
    "    Tdata['time_counter']=datetimeindex\n",
    "    Tdata_allm=[]\n",
    "    for loc in mooring_vars:\n",
    "        mdata=mooring_vars[loc]\n",
    "        Tdata_mooring=Tdata.sel(x=mdata.xx,y=mdata.yy)\n",
    "        Tdata_mooring=Tdata_mooring.interp(deptht=mdata.depth)\n",
    "        Tdata_allm.append(Tdata_mooring)\n",
    "    Tdata_allm=xr.concat(Tdata_allm,'loc')\n",
    "    print('Writing mooring t series to file')\n",
    "    Tdata_allm.drop_vars('time_counter_bounds').to_netcdf(f'../data/mooring_tseries_ens{ens}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2e9d9-3e68-47e8-a411-aebfdbb8b9c3",
   "metadata": {},
   "source": [
    "Do the same for CMIP6 models from ISMIP, using HadGEM3-GC31-MM instead of UKESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0b2f95-bce9-4dd9-a063-5ec0b20b62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/users/eboland/python')\n",
    "import baspy as bp\n",
    "import utils as ut\n",
    "import pandas as pd\n",
    "import xmip.preprocessing as pp #this makes all coordinates etc consistent across cmip6 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2687ee65-d3f1-4bce-9294-dd8b32b67cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_preprocessing(ds):\n",
    "    # fix naming\n",
    "    ds = ut.rename_cmip6(ds)\n",
    "    # promote empty dims to actual coordinates\n",
    "    ds = pp.promote_empty_dims(ds)\n",
    "    # demote coordinates from data_variables\n",
    "    ds = pp.correct_coordinates(ds)\n",
    "    # broadcast lon/lat\n",
    "    ds = pp.broadcast_lonlat(ds)\n",
    "    # shift all lons to consistent 0-360\n",
    "    ds = pp.correct_lon(ds)\n",
    "    # fix the units\n",
    "    ds = pp.correct_units(ds)\n",
    "    # rename the `bounds` according to their style (bound or vertex)\n",
    "  # ds = parse_lon_lat_bounds(ds)\n",
    "    # sort verticies in a consistent manner\n",
    "   # ds = sort_vertex_order(ds)\n",
    "    # convert vertex into bounds and vice versa, so both are available\n",
    "   # ds = maybe_convert_bounds_to_vertex(ds)\n",
    "   # ds = maybe_convert_vertex_to_bounds(ds)\n",
    "   # ds = fix_metadata(ds)\n",
    "   # ds = ds.drop_vars(_drop_coords, errors=\"ignore\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1761a4f7-9bff-4166-96d8-91e6a098c786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HadGEM3-GC31-MM\n",
      "File for r1i1p1f3 thetao exists, skipping\n",
      "File for r2i1p1f3 thetao exists, skipping\n",
      "File for r3i1p1f3 thetao exists, skipping\n",
      "File for r4i1p1f3 thetao exists, skipping\n",
      "File for r1i1p1f3 so exists, skipping\n",
      "File for r2i1p1f3 so exists, skipping\n",
      "File for r3i1p1f3 so exists, skipping\n",
      "File for r4i1p1f3 so exists, skipping\n",
      "GFDL-ESM4\n",
      "File for r1i1p1f1 thetao exists, skipping\n",
      "File for r1i1p1f1 thetao exists, skipping\n",
      "File for r1i1p1f1 so exists, skipping\n",
      "File for r1i1p1f1 so exists, skipping\n",
      "IPSL-CM6A-LR\n",
      "File for r1i1p1f1 thetao exists, skipping\n",
      "File for r2i1p1f1 thetao exists, skipping\n",
      "File for r3i1p1f1 thetao exists, skipping\n",
      "File for r4i1p1f1 thetao exists, skipping\n",
      "File for r5i1p1f1 thetao exists, skipping\n",
      "File for r6i1p1f1 thetao exists, skipping\n",
      "File for r7i1p1f1 thetao exists, skipping\n",
      "File for r8i1p1f1 thetao exists, skipping\n",
      "File for r9i1p1f1 thetao exists, skipping\n",
      "File for r1i1p1f1 so exists, skipping\n",
      "File for r2i1p1f1 so exists, skipping\n",
      "File for r3i1p1f1 so exists, skipping\n",
      "File for r4i1p1f1 so exists, skipping\n",
      "File for r5i1p1f1 so exists, skipping\n",
      "File for r6i1p1f1 so exists, skipping\n",
      "File for r7i1p1f1 so exists, skipping\n",
      "File for r8i1p1f1 so exists, skipping\n",
      "File for r9i1p1f1 so exists, skipping\n",
      "MPI-ESM1-2-HR\n",
      "Doing r1i1p1f1 thetao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/eboland/python/baspy/_catalogue.py:593: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  if len(pd.unique(list_file_extensions)) > 1:\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/plugins.py:168: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/plugins.py:168: RuntimeWarning: 'h5netcdf' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/users/eboland/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/plugins.py:168: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'pydap', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDoing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)     \n\u001b[1;32m     14\u001b[0m files \u001b[38;5;241m=\u001b[39m bp\u001b[38;5;241m.\u001b[39mget_files(row)\n\u001b[0;32m---> 15\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombined_preprocessing\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2000-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mindexes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], pd\u001b[38;5;241m.\u001b[39mDatetimeIndex):\n\u001b[1;32m     17\u001b[0m     datetimeindex \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mindexes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_datetimeindex()\n",
      "File \u001b[0;32m~/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/api.py:1025\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1023\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1025\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [open_(p, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m   1026\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/api.py:1025\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1023\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1025\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\u001b[43mopen_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m   1026\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/api.py:553\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(backend_kwargs)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    556\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.conda/envs/canari-dask-mine/lib/python3.10/site-packages/xarray/backends/plugins.py:197\u001b[0m, in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound the following matches with the input file in xarray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms IO \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'pydap', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "models=['HadGEM3-GC31-MM','GFDL-ESM4','IPSL-CM6A-LR','MPI-ESM1-2-HR', 'MRI-ESM2-0']\n",
    "#models=['MRI-ESM2-0',]\n",
    "for model in models:\n",
    "    print(model)\n",
    "    for var in ['thetao','so']:\n",
    "        df = bp.catalogue(dataset='cmip6',Var=[var,],Experiment=['historical',],CMOR='Omon',Model=model)\n",
    "        for ir,row in df.iterrows():\n",
    "        #    row=df.iloc[0]\n",
    "            run=row.RunID\n",
    "            if glob.glob(f'../data/mooring_tseries_{model}_{run}_{var}.nc'):\n",
    "                print(f'File for {run} {var} exists, skipping')\n",
    "                continue\n",
    "            print(f'Doing {run} {var}')     \n",
    "            files = bp.get_files(row)\n",
    "            data=xr.open_mfdataset(files,preprocess=combined_preprocessing).sel(time=slice('2000-01-01',None))\n",
    "            if not isinstance(data.indexes['time'], pd.DatetimeIndex):\n",
    "                datetimeindex = data.indexes['time'].to_datetimeindex()\n",
    "                data['time']=datetimeindex\n",
    "            data_allm=[]\n",
    "            for loc in mooring_vars:\n",
    "                mdata=mooring_vars[loc]\n",
    "                mlon=mdata.prof_lon.mean()\n",
    "                mlat=mdata.prof_lat.mean()\n",
    "                if mlon<0:\n",
    "                    mlon=360+mlon\n",
    "                [yy,xx]=ut.find_j_i(data,lon=mlon,lat=mlat)\n",
    "                if type(xx)==np.int64:\n",
    "                    data_mooring=data.isel(x=xx,y=yy)\n",
    "                else:\n",
    "                    data_mooring=data.isel(x=xx.compute(),y=yy.compute())\n",
    "                data_mooring=data_mooring.interp(lev=mdata.depth)\n",
    "                data_allm.append(data_mooring)\n",
    "            data_allm=xr.concat(data_allm,'loc')\n",
    "            data_allm=data_allm.assign_coords({'run':run,'model':model})\n",
    "            print('Writing mooring t series to file')\n",
    "            data_allm.to_netcdf(f'../data/mooring_tseries_{model}_{run}_{var}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ffad4b2-2206-40d1-82aa-85fa52e0903a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/badc/cmip6/data/CMIP6/CMIP/MPI-M/MPI-ESM1-2-HR/historical/r1i1p1f1/Omon/thetao/gn/v20190710//thetao_Omon_MPI-ESM1-2-HR_historical_r1i1p1f1_gn_185001-185412.nc'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3225763-6a8c-4e9e-b075-0c1f7bbaf984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CANARI-dask-mine",
   "language": "python",
   "name": "canari-dask-mine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
